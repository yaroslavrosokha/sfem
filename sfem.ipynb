{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background \n",
    " -- *From Romero and Rosokha ([2018](https://www.sciencedirect.com/science/article/pii/S0014292118300394),[2019a](https://www.aeaweb.org/articles?id=10.1257/mic.20160220),[2019b](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3290732)) and Rosokha and Wei ([2020](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3526505))*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy frequency estimation method (SFEM) is a finite-mixture estimation aproach to estimate the proportion of strategies in experimental data proposed by Dal Bo and Frechette (2011). The method works by first specifying the set of $K$ strategies considered by the modeler. Then, for each subject $n\\in \\{1,...,N\\}$, and each strategy $k\\in \\{1,...,K\\}$, the method prescribes to compare subject $n$'s actual play with how strategy $k$ would have played in her place. Let $C(k,n)$ denote the number of periods in which subject $n$'s play correctly matches the play of strategy $k$. Then, let $C$ denote a $K \\times N$ matrix of the number of correct matches for all combinations of subjects and strategies. Similarly, let $E$ denote a $K \\times N$ matrix of the number of mismatches when comparing subjects' play with what the strategies would do in their place. Then, define a Hadamard-product $P$:\n",
    "\n",
    "\\begin{equation}\n",
    "    P = \\beta^{C}\\circ(1-\\beta)^{E},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\beta$ is the probability that a subject plays according to a strategy and $(1-\\beta)$ the probability that the subjects deviates from that strategy. Thus,\n",
    "each entry $P(k,n)$ is the likelihood that the observed choices by subject $n$ were generated by strategy $k$. Then, using the matrix dot product, we define the log-likelihood function $\\mathcal{L}$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathcal{L}(\\beta,\\phi)= ln \\big( \\phi' \\cdot P \\big) \\cdot  \\mathbf{1} .\n",
    "\\end{equation}\n",
    "\n",
    "For this example, the set of strategies is the 20 strategies commonly used in the literature on repeated Prisoner's Dilemma (Fudenberg, Rand, and Dreber 2012). For details, see Appendix H of Romero and Rosokha (2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>supergame</th>\n",
       "      <th>period</th>\n",
       "      <th>action</th>\n",
       "      <th>opponentAction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1S1S01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1S1S01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1S1S01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1S1S01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T1S1S01</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  supergame  period action opponentAction\n",
       "0  T1S1S01          1       1      C              D\n",
       "1  T1S1S01          1       2      D              D\n",
       "2  T1S1S01          1       3      C              D\n",
       "3  T1S1S01          1       4      D              D\n",
       "4  T1S1S01          1       5      C              D"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For this example we will use data from Romero & Rosokha (2018)\n",
    "data=pd.read_csv('input\\\\action_data_RR2018.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data to supergames and periods of interest. \n",
    "# In RR2018 we focus on supermages 31-50 and restrict to at most 20 first periods \n",
    "# This is done so numerical issues when raising beta to large powers\n",
    "data = data[(data.supergame>30) & (data.supergame<51) & (data.period<21)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of subjects and maximum number of actions for each subject \n",
    "n_subjects = len(data.subject.unique())\n",
    "n_actions = data.groupby('subject').count().action.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create nan matrices of actions, matches, periods, and opponent's actions\n",
    "actions=np.empty((n_subjects,n_actions))\n",
    "actions.fill(np.nan)\n",
    "matches=np.empty((n_subjects,n_actions))\n",
    "matches.fill(np.nan)\n",
    "periods=np.empty((n_subjects,n_actions))\n",
    "periods.fill(np.nan)\n",
    "others=np.empty((n_subjects,n_actions))\n",
    "others.fill(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data into matrix format \n",
    "for i,sub in enumerate(data.subject.unique()):\n",
    "    \n",
    "    a = [x=='C' for x in data.action[data.subject==sub].tolist()]\n",
    "    m = data.supergame[data.subject==sub].tolist()\n",
    "    p = data.period[data.subject==sub].tolist()\n",
    "    o = [x=='C' for x in data.opponentAction[data.subject==sub].tolist()]\n",
    "    \n",
    "    n = len(a)\n",
    "    \n",
    "    actions[i,:n] = a\n",
    "    matches[i,:n] = m\n",
    "    periods[i,:n] = p\n",
    "    others[i,:n]  = o    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Simulate Strategies Against Opponent Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('input\\\\')\n",
    "import strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 strategies in the strategies.py file. \n",
      "The strategies are: ['s01_allc', 's02_alld', 's03_tft', 's04_dtft', 's05_tf2t', 's06_tf3t', 's07_2tft', 's08_2tf2t', 's09_t2', 's10_grim', 's11_grim2', 's12_grim3', 's13_wsls', 's14_2wsls', 's15_ctod', 's16_dtf2t', 's17_dtf3t', 's18_dgrim2', 's19_dgrim3', 's20_dcalt']\n"
     ]
    }
   ],
   "source": [
    "strats = []\n",
    "strat_names = []\n",
    "for i in dir(strategies):\n",
    "    s = getattr(strategies,i)\n",
    "    if callable(s):\n",
    "        strats.append(s)\n",
    "        strat_names.append(s.__name__)\n",
    "        \n",
    "\n",
    "n_strats = len(strats)\n",
    "print(\"There are\",n_strats,'strategies in the strategies.py file. \\nThe strategies are:',strat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each subject n and each strategy k compare subject n's actual play with how strategy k would have played.\n",
    "C = np.zeros((n_strats,n_subjects)) #Number of periods in which play matches\n",
    "E = np.zeros((n_strats,n_subjects)) #Number of periods in which play does not match\n",
    "for n in range(n_subjects):\n",
    "    for k in range(n_strats): \n",
    "\n",
    "        subChoice = actions[n]\n",
    "        otherChoice = others[n]\n",
    "        periodData = periods[n]\n",
    "\n",
    "        stratChoice = strats[k](otherChoice,periodData)\n",
    "\n",
    "        C[k,n]=np.sum(subChoice==stratChoice)\n",
    "        E[k,n]=np.sum((1-subChoice)==stratChoice)\n",
    "\n",
    "#Output C and E matrices as an intermediate step\n",
    "np.savetxt(\"output\\\\03-cMatrix.csv\", C, delimiter=\",\")\n",
    "np.savetxt(\"output\\\\03-eMatrix.csv\", E, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up the loglikelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelhood function takes as an input a vector of proportions of strategies and returns the likelihood value\n",
    "#Note cMat and eMat are global matrices that are updated externally for each treatment.\n",
    "def objective(x,args):\n",
    "    \n",
    "    C = args[0]\n",
    "    E = args[1]\n",
    "    \n",
    "    bc=np.power(x[0],C) #beta to the power of C\n",
    "    be=np.power(1-x[0],E) #beta to the power of E\n",
    "    prodBce = np.multiply(bc,be) #Hadamard product\n",
    "    \n",
    "    #maximum is taken so that there is no log(0) warning/error\n",
    "    res = np.log(np.maximum(np.dot(x[1:],prodBce),np.nextafter(0,1))).sum() \n",
    "    \n",
    "    return -res\n",
    "\n",
    "def constraint1(x):\n",
    "    \n",
    "    return x[1:].sum()-1\n",
    "\n",
    "#Set up the boundaries and constraints\n",
    "b0 = (np.nextafter(0.5,1),1-np.nextafter(0,1))\n",
    "b1 = (np.nextafter(0,1),1-np.nextafter(0,1))\n",
    "bnds = tuple([b0]+[b1]*n_strats) #Beta is at least .5\n",
    "con1 = {'type': 'eq', 'fun': constraint1} \n",
    "cons = ([con1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run likelihood maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some random starting point\n",
    "x0 = np.zeros(n_strats+1)\n",
    "x0[0] = .5+.5*np.random.random()\n",
    "temp = np.random.random(n_strats)\n",
    "x0[1:]=temp/temp.sum()\n",
    "\n",
    "bestX=x0\n",
    "bestObjective=objective(x0,[C,E])\n",
    "\n",
    "for k in range(50): #Do many times so that there is low chance of getting stuck in local optimum\n",
    "\n",
    "    x0 = np.zeros(n_strats+1)\n",
    "    x0[0] = .5+.5*np.random.random()\n",
    "    temp = np.random.random(n_strats)\n",
    "    x0[1:]=temp/temp.sum()\n",
    "\n",
    "    #Notice that we are minimizing the negative\n",
    "    solution = minimize(objective,x0,method='SLSQP',bounds=bnds,constraints=cons,args=([C,E]))\n",
    "    x = solution.x\n",
    "    obj = solution.fun\n",
    "\n",
    "    if bestObjective>obj:\n",
    "        bestObjective=obj\n",
    "        bestX=x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Estimates\n",
      "beta           0.9600\n",
      "s03_tft        0.3267\n",
      "s10_grim       0.1439\n",
      "s02_alld       0.1220\n",
      "s04_dtft       0.0976\n",
      "s07_2tft       0.0780\n",
      "s05_tf2t       0.0737\n",
      "s01_allc       0.0488\n",
      "s13_wsls       0.0245\n",
      "s16_dtf2t      0.0244\n",
      "s15_ctod       0.0218\n",
      "s11_grim2      0.0179\n",
      "s09_t2         0.0126\n",
      "s06_tf3t       0.0084\n",
      "s12_grim3      0.0000\n",
      "s14_2wsls      0.0000\n",
      "s08_2tf2t      0.0000\n",
      "s17_dtf3t      0.0000\n",
      "s18_dgrim2     0.0000\n",
      "s19_dgrim3     0.0000\n",
      "s20_dcalt      0.0000\n",
      "LL         -3871.8297\n"
     ]
    }
   ],
   "source": [
    "results=pd.DataFrame(bestX.round(4).tolist()+[np.round(-bestObjective,4)],index=['beta']+strat_names+['LL'])\n",
    "results=results.rename(columns={0:'Estimates'})\n",
    "results=results.sort_values(by=['Estimates'],ascending=False)\n",
    "print(results)\n",
    "results.to_csv(\"output\\\\06-sfem_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Dal Bó, P. and Fréchette, G.R., 2011. [The evolution of cooperation in infinitely repeated games: Experimental evidence.](https://www.aeaweb.org/articles?id=10.1257/aer.101.1.411) American Economic Review, 101(1), pp.411-29.\n",
    "\n",
    "- Dal Bó, P. and Fréchette, G.R., 2018. [On the determinants of cooperation in infinitely repeated games: A survey.](https://www.aeaweb.org/articles?id=10.1257/jel.20160980) Journal of Economic Literature, 56(1), pp.60-114.\n",
    "\n",
    "- Fudenberg, D., Rand, D.G. and Dreber, A., 2012. [Slow to anger and fast to forgive: Cooperation in an uncertain world.](https://www.aeaweb.org/articles?id=10.1257/aer.102.2.720) American Economic Review, 102(2), pp.720-49.\n",
    "\n",
    "- Romero, J. and Rosokha, Y., 2018. [Constructing strategies in the indefinitely repeated prisoner’s dilemma game.](https://www.sciencedirect.com/science/article/pii/S0014292118300394) European Economic Review, 104, pp.185-219.\n",
    "\n",
    "- Romero, J. and Rosokha, Y., 2019. [The Evolution of Cooperation: The Role of Costly Strategy Adjustments.](https://www.aeaweb.org/articles?id=10.1257/mic.20160220) American Economic Journal: Microeconomics, 11(1), pp.299-328.\n",
    "\n",
    "- Romero, J. and Rosokha, Y., 2019. [Mixed Strategies in the Indefinitely Repeated Prisoner's Dilemma.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3290732) Available at SSRN 3290732.\n",
    "\n",
    "- Rosokha, Y. and Wei, C., 2020. [Cooperation in Queueing Systems.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3526505) Available at SSRN 3526505.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
